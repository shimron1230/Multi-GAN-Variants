import argparse
import os
import numpy as np
import math
import torchvision.transforms as transforms
from torchvision.utils import save_image

from torch.utils.data import DataLoader
from torchvision import datasets
from torch.autograd import Variable

import torch.nn as nn
import torch

parser = argparse.ArgumentParser()
parser.add_argument("--gan_type", type=str, default='origin', help="type of gan model") # 'origin','softmax', 'arctan','ls'
parser.add_argument("--dataset", type=str, default='mnist', help="dataset to be modeled") # 'mnist','fashion-mnist', 'celeba'
parser.add_argument("--n_epochs", type=int, default=200, help="number of epochs of training") # 200, for celeba 50
parser.add_argument("--batch_size", type=int, default=64, help="size of the batches")
parser.add_argument("--lr", type=float, default=0.0002, help="adam: learning rate")
parser.add_argument("--b1", type=float, default=0.5, help="adam: decay of first order momentum of gradient")
parser.add_argument("--b2", type=float, default=0.999, help="adam: decay of first order momentum of gradient")
parser.add_argument("--n_cpu", type=int, default=8, help="number of cpu threads to use during batch generation")
parser.add_argument("--latent_dim", type=int, default=100, help="dimensionality of the latent space")
parser.add_argument("--img_size", type=int, default=28, help="size of each image dimension") # 28, for celeba 64
parser.add_argument("--channels", type=int, default=1, help="number of image channels") # 1, for celeba 3
parser.add_argument("--sample_interval", type=int, default=400, help="interval betwen image samples")
opt = parser.parse_args()
print(opt)

os.makedirs(f"images_{opt.gan_type}_{opt.dataset}", exist_ok=True)

img_shape = (opt.channels, opt.img_size, opt.img_size)

cuda = True if torch.cuda.is_available() else False

# load last checkpoint
def load_checkpoint(generator,discriminator,optimizer_G,optimizer_D,checkpoint_dir = ''):
    checkpoint_files = []
    if os.path.exists(checkpoint_dir):
        checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.startswith("checkpoint_epoch_")]

    if checkpoint_dir == '' or checkpoint_files == []:
        print("No checkpoint found, starting from scratch.")
        return generator,discriminator,optimizer_G,optimizer_D,0

    # find last checkpoint
    checkpoint_files.sort(key=lambda x: int(x.split("_")[-1].split(".")[0]))
    latest_checkpoint = checkpoint_files[-1]
    checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint)

    print(f"Loading checkpoint: {latest_checkpoint}")
    checkpoint = torch.load(checkpoint_path)

    generator.load_state_dict(checkpoint['generator_state_dict'])
    discriminator.load_state_dict(checkpoint['discriminator_state_dict'])
    optimizer_G.load_state_dict(checkpoint['optimizer_G_state_dict'])
    optimizer_D.load_state_dict(checkpoint['optimizer_D_state_dict'])
    start_epoch = checkpoint['epoch']

    return generator,discriminator,optimizer_G,optimizer_D,start_epoch

class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()

        def block(in_feat, out_feat, normalize=True):
            layers = [nn.Linear(in_feat, out_feat)]
            if normalize:
                layers.append(nn.BatchNorm1d(out_feat, 0.8))
            layers.append(nn.LeakyReLU(0.2, inplace=True))
            return layers

        self.model = nn.Sequential(
            *block(opt.latent_dim, 128, normalize=False),
            *block(128, 256),
            *block(256, 512),
            *block(512, 1024),
            nn.Linear(1024, int(np.prod(img_shape))),
            nn.Tanh()
        )

    def forward(self, z):
        img = self.model(z)
        img = img.view(img.shape[0], *img_shape)
        return img


class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        layers = [nn.Linear(int(np.prod(img_shape)), 512),
                  nn.LeakyReLU(0.2, inplace=True),
                  nn.Linear(512, 256),
                  nn.LeakyReLU(0.2, inplace=True),
                  nn.Linear(256, 1)]
        if opt.gan_type == 'origin':
            layers.append(nn.Sigmoid())
        self.model = nn.Sequential(*layers)

    def forward(self, img):
        img_flat = img.view(img.shape[0], -1)
        validity = self.model(img_flat)

        return validity


# Loss function
adversarial_loss = torch.nn.BCELoss()
mse_loss = nn.MSELoss()

# Initialize generator and discriminator
generator = Generator()
discriminator = Discriminator()

if cuda:
    generator.cuda()
    discriminator.cuda()
    adversarial_loss.cuda()
    mse_loss.cuda()

# Configure data loader
root = f"data/{opt.dataset}"
os.makedirs(root, exist_ok=True)
if opt.dataset == 'mnist':
    dataset = datasets.MNIST(
        root,
        train=True,
        download=True,
        transform=transforms.Compose(
            [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]
        ),
    )
elif opt.dataset == 'fashion-mnist':
    dataset = datasets.FashionMNIST(
        root,
        train=True,
        download=True,
        transform=transforms.Compose(
            [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]
        ),
    )
elif opt.dataset == 'celeba':
    dataset = datasets.CelebA(
        root,
        split='train',
        download=True,
        transform=transforms.Compose(
            [
                transforms.Resize((opt.img_size,opt.img_size)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])]
        ),
    )
else:
    raise ValueError('Dataset not implemented')
dataloader = torch.utils.data.DataLoader(
    dataset,
    batch_size=opt.batch_size,
    shuffle=True,
)

# Optimizers
optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))
optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))

generator,discriminator,optimizer_G,optimizer_D,start_epoch = load_checkpoint(generator,discriminator,optimizer_G,optimizer_D,checkpoint_dir = f'checkpoints_{opt.gan_type}_{opt.dataset}')
Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor


def log(x):
    return torch.log(x + 1e-8)

def atan_prob(x):
    return torch.tensor(0.5)+torch.mul(torch.atan(x),1/math.pi)

# ----------
#  Training
# ----------

for epoch in range(start_epoch,opt.n_epochs):
    for i, (imgs, _) in enumerate(dataloader):

        d_loss = 0
        g_loss = 0
        real_imgs = Variable(imgs.type(Tensor))
        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))
        gen_imgs = generator(z)

        if opt.gan_type == 'origin':
            # Adversarial ground truths
            valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)
            fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)

            optimizer_G.zero_grad()
            g_loss = adversarial_loss(discriminator(gen_imgs), valid)
            g_loss.backward()
            optimizer_G.step()

            optimizer_D.zero_grad()
            real_loss = adversarial_loss(discriminator(real_imgs), valid)
            fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)
            d_loss = (real_loss + fake_loss) / 2
            d_loss.backward()
            optimizer_D.step()

        elif opt.gan_type == 'softmax':
            batch_size = imgs.shape[0]
            # Adversarial ground truths for softmax gan
            g_target = 1 / (batch_size * 2)
            d_target = 1 / batch_size

            optimizer_D.zero_grad()
            d_real = discriminator(real_imgs)
            d_fake = discriminator(gen_imgs)
            # Partition function
            Z = torch.sum(torch.exp(-d_real)) + torch.sum(torch.exp(-d_fake))
            d_loss = d_target * torch.sum(d_real) + log(Z)
            d_loss.backward(retain_graph=True)
            optimizer_D.step()

            optimizer_G.zero_grad()
            d_real = discriminator(real_imgs)
            d_fake = discriminator(gen_imgs)
            # Partition function
            Z = torch.sum(torch.exp(-d_real)) + torch.sum(torch.exp(-d_fake))
            g_loss = g_target * (torch.sum(d_real) + torch.sum(d_fake)) + log(Z)
            g_loss.backward()
            optimizer_G.step()

        elif opt.gan_type == 'arctan':
            batch_size = imgs.shape[0]
            # Adversarial ground truths like softmax gan
            g_target = 1 / (batch_size * 2)
            d_target = 1 / batch_size

            optimizer_D.zero_grad()
            d_real = discriminator(real_imgs)
            d_fake = discriminator(gen_imgs)
            # Partition function
            Z = torch.sum(atan_prob(d_real)) + torch.sum(atan_prob(d_fake))
            d_loss = -d_target * torch.sum(log(atan_prob(d_real)/Z))
            d_loss.backward(retain_graph=True)
            optimizer_D.step()

            optimizer_G.zero_grad()
            d_real = discriminator(real_imgs)
            d_fake = discriminator(gen_imgs)
            # Partition function
            Z = torch.sum(atan_prob(d_real)) + torch.sum(atan_prob(d_fake))
            g_loss = -g_target * (torch.sum(log(atan_prob(d_real)/Z)) + torch.sum(log(atan_prob(d_fake)/Z)))
            g_loss.backward()
            optimizer_G.step()

        elif opt.gan_type == 'ls':
            batch_size = imgs.shape[0]
            # Adversarial ground truths like softmax gan
            g_target = 1 / (batch_size * 2)
            d_target = 1 / batch_size

            optimizer_D.zero_grad()
            d_real = discriminator(real_imgs)
            d_fake = discriminator(gen_imgs)
            # Partition function
            Z = torch.sum(torch.exp(d_real)) + torch.sum(torch.exp(d_fake))
            d_loss = mse_loss(torch.full((batch_size,1),d_target),torch.exp(d_real)/Z) + mse_loss(torch.full((batch_size,1),0.0),torch.exp(d_fake)/Z)
            d_loss.backward(retain_graph=True)
            optimizer_D.step()

            optimizer_G.zero_grad()
            d_real = discriminator(real_imgs)
            d_fake = discriminator(gen_imgs)
            # Partition function
            Z = torch.sum(torch.exp(d_real)) + torch.sum(torch.exp(d_fake))
            g_loss =  mse_loss(torch.full((batch_size,1),g_target),torch.exp(d_real)/Z) + mse_loss(torch.full((batch_size,1),g_target),torch.exp(d_fake)/Z)
            g_loss.backward()
            optimizer_G.step()
        else:
            raise ValueError('GAN model not implemented')
        print(
            "[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]"
            % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())
        )

        batches_done = epoch * len(dataloader) + i
        if batches_done % opt.sample_interval == 0:
            save_image(gen_imgs.data[:25], f"images_{opt.gan_type}_{opt.dataset}/%d.png" % batches_done, nrow=5, normalize=True)

    # save checkpoint for each 10 epochs
    checkpoint_dir = f'checkpoints_{opt.gan_type}_{opt.dataset}'
    if checkpoint_dir != '' and (epoch + 1) % 10 == 0:
        os.makedirs(checkpoint_dir, exist_ok=True)
        checkpoint_path = os.path.join(checkpoint_dir, f"checkpoint_epoch_{epoch + 1}.pth")
        torch.save({
            'epoch': epoch + 1,
            'generator_state_dict': generator.state_dict(),
            'discriminator_state_dict': discriminator.state_dict(),
            'optimizer_G_state_dict': optimizer_G.state_dict(),
            'optimizer_D_state_dict': optimizer_D.state_dict(),
        }, checkpoint_path)
